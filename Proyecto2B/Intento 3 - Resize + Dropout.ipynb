{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intento 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este intento es similar al anterior con la única diferencia de que el *frame size* empleado es (96,96) en lugar de (64,64). Además emos usado una tasa de *dropout* algo mayor (del 50% en lugar del 30%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dsvzwGy-bWrT"
   },
   "source": [
    "## 0. Descarga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "w-fLk6oobhF2",
    "outputId": "0c80eec8-91fa-4455-be82-940db7c2c4e0"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "train_ds_path  ='C:/Users/Usuario/Documents/Master/Aprendizaje Profundo/Udemy/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/training_set'\n",
    "test_ds_path   ='C:/Users/Usuario/Documents/Master/Aprendizaje Profundo/Udemy/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/test_set'\n",
    "cat_or_dog_path='C:/Users/Usuario/Documents/Master/Aprendizaje Profundo/Udemy/deeplearning-az/datasets/Part 2 - Convolutional Neural Networks (CNN)/dataset/single_prediction/cat_or_dog_1.jpg'\n",
    "\n",
    "\n",
    "#train_ds_path  ='.\\\\data\\\\training_set'\n",
    "#test_ds_path   ='.\\\\data\\\\test_set'\n",
    "#cat_or_dog_path='.\\\\data\\\\single_prediction\\\\cat_or_dog_1.jpg'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, importar las librerías y paquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "# Nota, algunas capas no están importadas aquí y se importan directamente en el código con tf.keras.laters.[CAPA]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import random as rn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fijamos seeds para poder reproducir resultados (aunque aun así a veces no lo conseguimos, probablementa haya inicializaciones que no dependan de estas seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(42)\n",
    "rn.seed(12345)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kj7yYesKbctW"
   },
   "source": [
    "## 1. Construcción del modelo CNN añadiendo un tamaño de imagen mayor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AtczsRskbj2F"
   },
   "source": [
    "El tamaño de imagen que emplearemos será de 96x96, y el dropout rate es del 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kYdJsjsZCR8"
   },
   "outputs": [],
   "source": [
    "frame_size = (96, 96)\n",
    "\"\"\"\n",
    "esta dupla nos permitirá parametrizar la resolución\n",
    "de entrada de las imágenes\n",
    "\"\"\"\n",
    "\n",
    "def crear_clasificador_intento2():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Conv2D(filters = 32,kernel_size = (3, 3), \n",
    "                      input_shape = (*frame_size, 3), activation = \"relu\"))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    classifier.add(Conv2D(filters = 32,kernel_size = (3, 3), activation = \"relu\"))\n",
    "    classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(units = 128, activation = \"relu\"))\n",
    "    classifier.add(Dropout(0.3))\n",
    "    classifier.add(Dense(units = 1, activation = \"sigmoid\"))    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7INHvHmcFdL"
   },
   "source": [
    "## 2. Entrenamiento del intento 2\n",
    "\n",
    "En primer lugar instanciamos nuestro modelo y compilamos usando:\n",
    "* Un optimizador Adam. La learning rate que emplea por defecto es 0.001\n",
    "* Binary cross entropy como función de coste a minimizar.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uc7pBop7ZLeN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 94, 94, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 47, 47, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 45, 45, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 15488)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1982592   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,992,865\n",
      "Trainable params: 1,992,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier = crear_clasificador_intento2()\n",
    "classifier.compile(optimizer = \"adam\", \n",
    "                   loss = \"binary_crossentropy\", \n",
    "                   metrics = [\"accuracy\"])\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En segundo lugar, generamos los datasets de entrenamiento y test. Emplearemos un tamaño de batch de 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "BYgCwVDFZMrU",
    "outputId": "641d711f-0723-447f-811b-1c1aaa639274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size=32 \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_dataset = train_datagen.flow_from_directory(train_ds_path,\n",
    "                                                     target_size=frame_size,\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='binary')\n",
    "\n",
    "testing_dataset = test_datagen.flow_from_directory(test_ds_path,\n",
    "                                                   target_size=frame_size,                                                   \n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el callback y realizamos el entrenamiento con las condiciones descritas en la sección de introducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.6808 - accuracy: 0.5705 - val_loss: 0.6015 - val_accuracy: 0.6755\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.5921 - accuracy: 0.6837 - val_loss: 0.5527 - val_accuracy: 0.7220\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.5401 - accuracy: 0.7212 - val_loss: 0.5366 - val_accuracy: 0.7390\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 36s 144ms/step - loss: 0.5216 - accuracy: 0.7476 - val_loss: 0.4993 - val_accuracy: 0.7560\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 48s 191ms/step - loss: 0.4813 - accuracy: 0.7595 - val_loss: 0.4875 - val_accuracy: 0.7605\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 51s 202ms/step - loss: 0.4782 - accuracy: 0.7798 - val_loss: 0.5000 - val_accuracy: 0.7655\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 52s 206ms/step - loss: 0.4559 - accuracy: 0.7773 - val_loss: 0.4705 - val_accuracy: 0.7790\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 49s 196ms/step - loss: 0.4415 - accuracy: 0.7942 - val_loss: 0.4802 - val_accuracy: 0.7800\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 51s 200ms/step - loss: 0.4200 - accuracy: 0.8071 - val_loss: 0.4457 - val_accuracy: 0.7955\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 51s 204ms/step - loss: 0.4033 - accuracy: 0.8203 - val_loss: 0.4808 - val_accuracy: 0.7970\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 51s 203ms/step - loss: 0.3832 - accuracy: 0.8235 - val_loss: 0.4549 - val_accuracy: 0.7925\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 51s 204ms/step - loss: 0.3679 - accuracy: 0.8400 - val_loss: 0.4687 - val_accuracy: 0.7995\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 52s 205ms/step - loss: 0.3771 - accuracy: 0.8321 - val_loss: 0.4950 - val_accuracy: 0.7895\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 51s 204ms/step - loss: 0.3499 - accuracy: 0.8455 - val_loss: 0.4840 - val_accuracy: 0.7935\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 51s 203ms/step - loss: 0.3513 - accuracy: 0.8403 - val_loss: 0.4694 - val_accuracy: 0.7990\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 51s 202ms/step - loss: 0.3377 - accuracy: 0.8500 - val_loss: 0.4739 - val_accuracy: 0.8055\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 52s 206ms/step - loss: 0.3351 - accuracy: 0.8514 - val_loss: 0.4828 - val_accuracy: 0.8080\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 50s 200ms/step - loss: 0.3082 - accuracy: 0.8712 - val_loss: 0.4865 - val_accuracy: 0.8070\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 51s 204ms/step - loss: 0.3013 - accuracy: 0.8748 - val_loss: 0.5454 - val_accuracy: 0.7910\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 52s 206ms/step - loss: 0.2903 - accuracy: 0.8783 - val_loss: 0.4950 - val_accuracy: 0.8035\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 51s 202ms/step - loss: 0.2914 - accuracy: 0.8778 - val_loss: 0.5043 - val_accuracy: 0.8130\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 52s 205ms/step - loss: 0.2827 - accuracy: 0.8810 - val_loss: 0.4590 - val_accuracy: 0.8210 2 - ETA: 1s - loss: 0.282\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 52s 206ms/step - loss: 0.2637 - accuracy: 0.8913 - val_loss: 0.5329 - val_accuracy: 0.7905\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 52s 206ms/step - loss: 0.2646 - accuracy: 0.8918 - val_loss: 0.5540 - val_accuracy: 0.8045\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 51s 204ms/step - loss: 0.2652 - accuracy: 0.8937 - val_loss: 0.5182 - val_accuracy: 0.8100\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 52s 206ms/step - loss: 0.2231 - accuracy: 0.9157 - val_loss: 0.5641 - val_accuracy: 0.8080: 0.2179 -  - ETA: 26s - loss: 0.2183 - accuracy:\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 51s 203ms/step - loss: 0.2270 - accuracy: 0.9084 - val_loss: 0.5729 - val_accuracy: 0.8025\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 51s 204ms/step - loss: 0.2161 - accuracy: 0.9080 - val_loss: 0.5320 - val_accuracy: 0.8165\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 47s 188ms/step - loss: 0.1940 - accuracy: 0.9197 - val_loss: 0.5607 - val_accuracy: 0.8180\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.2031 - accuracy: 0.9195 - val_loss: 0.5985 - val_accuracy: 0.7970\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1970 - accuracy: 0.9207 - val_loss: 0.5450 - val_accuracy: 0.8160\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1962 - accuracy: 0.9181 - val_loss: 0.5906 - val_accuracy: 0.8135\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1892 - accuracy: 0.9225 - val_loss: 0.5804 - val_accuracy: 0.8195\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1845 - accuracy: 0.9238 - val_loss: 0.5593 - val_accuracy: 0.8230\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1653 - accuracy: 0.9316 - val_loss: 0.6065 - val_accuracy: 0.8220\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1657 - accuracy: 0.9317 - val_loss: 0.6520 - val_accuracy: 0.8150\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1611 - accuracy: 0.9365 - val_loss: 0.6151 - val_accuracy: 0.8140\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.1597 - accuracy: 0.9357 - val_loss: 0.6640 - val_accuracy: 0.8150\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.1565 - accuracy: 0.9342 - val_loss: 0.6872 - val_accuracy: 0.8040\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1593 - accuracy: 0.9425 - val_loss: 0.6456 - val_accuracy: 0.8155\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.1539 - accuracy: 0.9433 - val_loss: 0.6664 - val_accuracy: 0.8180\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1421 - accuracy: 0.9470 - val_loss: 0.6420 - val_accuracy: 0.8060\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1532 - accuracy: 0.9403 - val_loss: 0.7020 - val_accuracy: 0.8305\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1328 - accuracy: 0.9510 - val_loss: 0.7258 - val_accuracy: 0.8090\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1349 - accuracy: 0.9466 - val_loss: 0.7336 - val_accuracy: 0.8020\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1359 - accuracy: 0.9474 - val_loss: 0.6755 - val_accuracy: 0.8160\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1291 - accuracy: 0.9494 - val_loss: 0.6929 - val_accuracy: 0.8190\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1347 - accuracy: 0.9446 - val_loss: 0.8148 - val_accuracy: 0.8080\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1311 - accuracy: 0.9527 - val_loss: 0.7355 - val_accuracy: 0.8160\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1205 - accuracy: 0.9564 - val_loss: 0.7563 - val_accuracy: 0.8085\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1175 - accuracy: 0.9570 - val_loss: 0.6976 - val_accuracy: 0.8150\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1385 - accuracy: 0.9458 - val_loss: 0.7039 - val_accuracy: 0.8205\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1217 - accuracy: 0.9521 - val_loss: 0.6861 - val_accuracy: 0.8195\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1074 - accuracy: 0.9563 - val_loss: 0.7655 - val_accuracy: 0.8030\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1110 - accuracy: 0.9606 - val_loss: 0.8339 - val_accuracy: 0.8015\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 31s 122ms/step - loss: 0.1006 - accuracy: 0.9606 - val_loss: 0.7995 - val_accuracy: 0.8090\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1011 - accuracy: 0.9592 - val_loss: 0.7548 - val_accuracy: 0.8260\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1106 - accuracy: 0.9574 - val_loss: 0.8070 - val_accuracy: 0.8180\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1029 - accuracy: 0.9596 - val_loss: 0.7569 - val_accuracy: 0.8225\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0976 - accuracy: 0.9592 - val_loss: 0.7856 - val_accuracy: 0.8130\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1067 - accuracy: 0.9613 - val_loss: 0.7978 - val_accuracy: 0.8155\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1011 - accuracy: 0.9649 - val_loss: 0.8525 - val_accuracy: 0.8250\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0950 - accuracy: 0.9646 - val_loss: 0.8882 - val_accuracy: 0.8065\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0997 - accuracy: 0.9637 - val_loss: 0.7904 - val_accuracy: 0.8185\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1111 - accuracy: 0.9585 - val_loss: 0.8236 - val_accuracy: 0.8145\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.0889 - accuracy: 0.9684 - val_loss: 0.8733 - val_accuracy: 0.8200\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.0927 - accuracy: 0.9666 - val_loss: 0.9019 - val_accuracy: 0.8110\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0903 - accuracy: 0.9667 - val_loss: 0.8887 - val_accuracy: 0.8165\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0943 - accuracy: 0.9666 - val_loss: 0.8939 - val_accuracy: 0.8015\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0844 - accuracy: 0.9669 - val_loss: 0.8512 - val_accuracy: 0.8215\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.0839 - accuracy: 0.9692 - val_loss: 0.8960 - val_accuracy: 0.8235\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 31s 121ms/step - loss: 0.0812 - accuracy: 0.9709 - val_loss: 0.9073 - val_accuracy: 0.8240\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.0922 - accuracy: 0.9651 - val_loss: 0.8398 - val_accuracy: 0.8200\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.0847 - accuracy: 0.9671 - val_loss: 0.9049 - val_accuracy: 0.7940\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.0947 - accuracy: 0.9645 - val_loss: 0.8411 - val_accuracy: 0.8140\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 31s 125ms/step - loss: 0.0913 - accuracy: 0.9679 - val_loss: 0.9235 - val_accuracy: 0.8090\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0865 - accuracy: 0.9651 - val_loss: 0.9955 - val_accuracy: 0.8150\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0945 - accuracy: 0.9626 - val_loss: 0.8622 - val_accuracy: 0.8120\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0893 - accuracy: 0.9653 - val_loss: 0.9019 - val_accuracy: 0.8105\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0725 - accuracy: 0.9726 - val_loss: 0.9189 - val_accuracy: 0.8130\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0906 - accuracy: 0.9687 - val_loss: 1.0249 - val_accuracy: 0.7915\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0854 - accuracy: 0.9687 - val_loss: 0.8745 - val_accuracy: 0.8220\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0860 - accuracy: 0.9700 - val_loss: 0.8928 - val_accuracy: 0.8075\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0865 - accuracy: 0.9706 - val_loss: 0.8927 - val_accuracy: 0.8125\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.0680 - accuracy: 0.9740 - val_loss: 0.8738 - val_accuracy: 0.8125\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.0706 - accuracy: 0.9758 - val_loss: 0.9148 - val_accuracy: 0.8150\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0596 - accuracy: 0.9787 - val_loss: 0.9912 - val_accuracy: 0.8170\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0663 - accuracy: 0.9757 - val_loss: 0.9598 - val_accuracy: 0.8110\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0930 - accuracy: 0.9657 - val_loss: 0.9194 - val_accuracy: 0.8210\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.0823 - accuracy: 0.9687 - val_loss: 0.9145 - val_accuracy: 0.8015\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0931 - accuracy: 0.9674 - val_loss: 0.9383 - val_accuracy: 0.8255\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0688 - accuracy: 0.9746 - val_loss: 1.0724 - val_accuracy: 0.8125\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0673 - accuracy: 0.9736 - val_loss: 0.9429 - val_accuracy: 0.8235\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.0885 - accuracy: 0.9682 - val_loss: 0.9551 - val_accuracy: 0.8175\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0729 - accuracy: 0.9745 - val_loss: 0.9136 - val_accuracy: 0.8145\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 31s 122ms/step - loss: 0.0694 - accuracy: 0.9735 - val_loss: 1.0607 - val_accuracy: 0.7930\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0754 - accuracy: 0.9748 - val_loss: 1.0211 - val_accuracy: 0.8180\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.0773 - accuracy: 0.9726 - val_loss: 1.1429 - val_accuracy: 0.8020\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 32s 126ms/step - loss: 0.0687 - accuracy: 0.9747 - val_loss: 0.9836 - val_accuracy: 0.8160\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 32s 125ms/step - loss: 0.0562 - accuracy: 0.9799 - val_loss: 0.9661 - val_accuracy: 0.8115\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta = 0, patience=5),\n",
    "]                                                   \n",
    "                                                   \n",
    "history1 = classifier.fit(x=training_dataset,\n",
    "                         steps_per_epoch=8000/batch_size,\n",
    "                         epochs=100,\n",
    "                         validation_data=testing_dataset,\n",
    "                         validation_steps=2000/batch_size,\n",
    "                         workers=4) # \"Si pedimos más de un proceso el rendimiento mejora un poco\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploteamos el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a72c62acc41b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cross entropy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mplot_resultados_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_resultados_training(history):\n",
    "    fig, axes = plt.subplots(1,2, figsize=(18,6))\n",
    "    axes[0].plot(history.history['accuracy'], label='Train')\n",
    "    axes[0].plot(history.history['val_accuracy'], label='Validation')\n",
    "    axes[0].legend()\n",
    "    axes[0].set_title('Accuracy')\n",
    "    axes[1].plot(history.history['loss'], label='Train')\n",
    "    axes[1].plot(history.history['val_loss'], label='Validation')\n",
    "    axes[1].set_title('Cross entropy')\n",
    "plot_resultados_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('.\\\\models\\\\clasificador3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentario\n",
    "La divergencia entre las precisiones de entrenamiento y validación ha empeorado. Aunque cabe destacar que la red ha mejorado su tasa de precisión\n",
    "en entrenamiento, seguramente debido a que las imágenes aportan más información útil.\n",
    "\n",
    "## Propuesta de mejora\n",
    "Seguiremos aumentando el parámetro del índice de olvido hasta su máximo teórico de 0.5 para ver si esto mejora el sobre-entrenamiento."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CNN.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
